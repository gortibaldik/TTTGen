\chapter{Experiments} \label{experiments_chapter}

In the previous chapters I have presented the dataset (chapter \ref{chapter:data}), and discussed challenges which arise from its properties (chapter \ref{chapPreproc}). Next I described the neural network architectures (chapter \ref{neural_nets_chapter}) which served as building blocks for the models introduced in chapter \ref{model_chapter}. Now I want to connect all the parts together, elaborate on the trainining of the models and analyze their results.

Let me recap the main challenges we face, and hypothesize about the ideal generation system. Firstly, the target summaries are really long. The ideal system should remember what has already been generated and shouldn't produce duplications. Secondly, the targets contain a lot of facts based on the input structured data. The ideal system should copy these facts from the input and reduce \emph{hallucinations}. Lastly, the generated text should be as close to English as possible \emph{while meeting the requirements described previously}.

\section{Evaluation Methods}

During evaluation I want to measure which model resembles the hypothetical ideal model the most. To do so, I report the BLEU score \citep{papineni2002} of the generated summaries on the development and test sets. Although it is the gold standard, there are many people arguing against its usage as a performance metric \citep{celikyilmaz2021evaluation}, and I found that the networks producing more factually correct statements doesn't score better. Therefore I also manually evaluate a subset of the generated summaries. I focus on the factual correctness, the reduplications and inter-sentential coherence. (If two sentences in the generated summary doesn't contradict each other)

\citep{wiseman2017} proposed three custom automated metrics to evaluate the performance of their models. They call them \emph{Content Selection} ("how well the generated document matches the gold document in terms of selecting which records to generate"), \emph{Relation Generation} ("how well the system is able to generate text containing factual (i.e., correct) records") and \emph{Content Ordering} ("how well the system orders the records it chooses to discuss"). The metrics are implemented in outdated neural network framework \emph{Torch} and I wasn't able to execute it on my computers. After discussions with my advisor we agreed to not adopt these methods.

\section{Baseline Model}

At first I describe the hyperparameter choice. I embed the \emph{type} and \emph{home/away} fields to $\mathbb{R}^{300}$ and \emph{entity} and \emph{value} fields to $\mathbb{R}^{600}$. All the hidden states of the LSTMs as well as the representation of the input record (produced by Feed-Forward Network as described in \ref{sec_baseline_model_rotowire}) are in $\mathbb{R}^{600}$.

\subsection{Results}



\section{Implementation Details}

As stated in the introduction this thesis is highly theoretical and experimental. The implementation serves as proof-of-concept and doesn't aim to be used in the production.

All the models and preprocessing methods were developed in \emph{python 3.8} and \emph{tensorflow 2.4.1}. However the code is compatible with \emph{python 3.6} and \emph{tensorflow 2.3} (the versions used on Artifical Intelligence Cluster (AIC) where the training was executed). The implementation is divided into two modules, \emph{preprocessing} and \emph{training}.

\subsection{Preprocessing Module}

The preprocessing happens in four steps.
\begin{enumerate}
    \item Filtering out the faulty data-points (section \ref{cleaning_section}) from the original dataset.
    \item Extraction and transformation of the summaries from the cleaned dataset.
    \item Byte Pair Encoding of the summaries. (As explained in section \ref{bpeSection} I use the \emph{subword-nmt} module by \citep{sennrich2016}.)
    \item Construction of the dataset from the encoded summaries and the cleaned data. 
\end{enumerate}
Each step is implemented in \emph{python} and the steps are connected by a shell script.

\subsection{Training Module}

The training module contains implementation of layers and models discussed in previous chapters as well as training, evaluation and inference methods. It makes use of \emph{graph execution}\footnote{\url{https://www.tensorflow.org/guide/intro_to_graphs}} during training and \emph{eager execution}\footnote{\url{https://www.tensorflow.org/guide/eager}} during evaluation and prediction.

The code is available at \url{https://github.com/gortibaldik/TTTGen/}.